"""
æ‰‹å‹¢æ•¸å­—è¾¨è­˜ä¸»ç¨‹å¼
ä½¿ç”¨ Logitech C270 æ”åƒé ­é€²è¡Œå¯¦æ™‚æ‰‹å‹¢è¾¨è­˜
"""
import cv2
import time
from hand_detector import HandDetector
from gesture_recognizer import GestureRecognizer


def main():
    # è¨­å®šåƒæ•¸
    camera_width = 640
    camera_height = 480
    camera_id = 0  # é€šå¸¸æ˜¯ 0ï¼Œå¦‚æœæœ‰å¤šå€‹æ”åƒé ­å¯ä»¥å˜—è©¦ 1, 2...
    
    # åˆå§‹åŒ–æ”åƒé ­
    print("æ­£åœ¨åˆå§‹åŒ–æ”åƒé ­...")
    cap = cv2.VideoCapture(camera_id)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, camera_width)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, camera_height)
    
    if not cap.isOpened():
        print(f"éŒ¯èª¤ï¼šç„¡æ³•æ‰“é–‹æ”åƒé ­ {camera_id}")
        print("è«‹ç¢ºèªï¼š")
        print("1. æ”åƒé ­å·²æ­£ç¢ºé€£æ¥")
        print("2. æ”åƒé ­é©…å‹•å·²å®‰è£")
        print("3. æ‚¨æœ‰è¨ªå•æ”åƒé ­çš„æ¬Šé™")
        return
    
    print(f"æ”åƒé ­åˆå§‹åŒ–æˆåŠŸï¼è§£æåº¦: {camera_width}x{camera_height}")
    
    # åˆå§‹åŒ–æ‰‹éƒ¨æª¢æ¸¬å™¨å’Œæ‰‹å‹¢è¾¨è­˜å™¨ï¼ˆé›™æ‰‹æ¨¡å¼ï¼‰
    detector = HandDetector(max_hands=2, detection_confidence=0.7)
    recognizer = GestureRecognizer()
    
    # FPS è¨ˆç®—
    previous_time = 0
    
    # ç©©å®šæ€§è¨ˆæ•¸å™¨ï¼ˆé¿å…èª¤åˆ¤ï¼‰
    stable_gesture = -1
    stable_count = 0
    stable_threshold = 5  # éœ€è¦é€£çºŒæª¢æ¸¬åˆ°ç›¸åŒæ‰‹å‹¢ 5 æ¬¡æ‰é¡¯ç¤º
    
    print("\né–‹å§‹è¾¨è­˜...")
    print("æŒ‰ 'q' æˆ– 'ESC' é€€å‡ºç¨‹å¼")
    print("æŒ‰ 'h' é¡¯ç¤ºå¹«åŠ©ä¿¡æ¯")
    print("-" * 50)
    
    while True:
        success, img = cap.read()
        
        if not success:
            print("è­¦å‘Šï¼šç„¡æ³•è®€å–æ”åƒé ­ç•«é¢")
            break
        
        # æ°´å¹³ç¿»è½‰å½±åƒï¼ˆé¡åƒæ•ˆæœï¼‰
        img = cv2.flip(img, 1)
        
        # æª¢æ¸¬æ‰‹éƒ¨
        img = detector.find_hands(img, draw=True)
        hand_count = detector.get_hand_count()
        
        # é›™æ‰‹è¾¨è­˜æ‰‹å‹¢
        if hand_count > 0:
            hands_data = []
            
            # éæ­·æ‰€æœ‰æª¢æ¸¬åˆ°çš„æ‰‹
            for hand_no in range(hand_count):
                hand_landmarks = detector.find_position(img, hand_no)
                if len(hand_landmarks) != 0:
                    fingers = detector.fingers_up(hand_landmarks)
                    number, gesture_name = recognizer.recognize_number(fingers)
                    wrist_x = hand_landmarks[0][1]
                    
                    hands_data.append({
                        'number': number,
                        'name': gesture_name,
                        'wrist_x': wrist_x
                    })
            
            # æ ¹æ“š X åº§æ¨™æ’åºï¼ˆç”±å·¦åˆ°å³ï¼‰
            hands_data.sort(key=lambda h: h['wrist_x'])
            
            # çµ„åˆæ‰‹å‹¢çµæœ
            if len(hands_data) == 1:
                combined_number = hands_data[0]['number']
                combined_name = hands_data[0]['name']
            elif len(hands_data) == 2:
                left_hand = hands_data[0]
                right_hand = hands_data[1]
                
                if (0 <= left_hand['number'] <= 9 and 
                    0 <= right_hand['number'] <= 9):
                    # çµ„æˆå…©ä½æ•¸
                    combined_number = left_hand['number'] * 10 + right_hand['number']
                    combined_name = str(combined_number)
                else:
                    # çµ„åˆæ‰‹å‹¢
                    combined_number = -2
                    combined_name = f"{left_hand['name']}+{right_hand['name']}"
            else:
                combined_number = -1
                combined_name = "Unknown"
            
            # ç©©å®šæ€§æª¢æ¸¬
            if combined_name == stable_gesture:
                stable_count += 1
            else:
                stable_gesture = combined_name
                stable_count = 1
            
            # å¦‚æœæ‰‹å‹¢ç©©å®šï¼Œå‰‡é¡¯ç¤º
            if stable_count >= stable_threshold and combined_number != -1:
                # æº–å‚™é¡¯ç¤ºæ–‡å­—
                if combined_number == -2:
                    display_text = combined_name
                elif 10 <= combined_number <= 99:
                    display_text = f"Number: {combined_number}"
                elif combined_number > 99:
                    display_text = combined_name
                else:
                    display_text = f"Number: {combined_number}"
                
                # å‹•æ…‹èª¿æ•´èƒŒæ™¯æ¡†å¯¬åº¦
                box_width = max(350, len(display_text) * 15 + 50)
                
                # èƒŒæ™¯æ¡†
                cv2.rectangle(img, (10, 10), (box_width, 80), (0, 128, 0), -1)
                cv2.rectangle(img, (10, 10), (box_width, 80), (255, 255, 255), 2)
                
                # é¡¯ç¤ºæ–‡å­—
                cv2.putText(img, display_text, (20, 55), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)
                
                # åœ¨çµ‚ç«¯è¼¸å‡º
                print(f"\rè­˜åˆ¥çµæœ: {display_text}", end="", flush=True)
        else:
            # æ²’æœ‰æª¢æ¸¬åˆ°æ‰‹éƒ¨
            stable_gesture = -1
            stable_count = 0
            cv2.putText(img, "Place your hands in front of camera", (20, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # è¨ˆç®—ä¸¦é¡¯ç¤º FPS
        current_time = time.time()
        fps = 1 / (current_time - previous_time) if (current_time - previous_time) > 0 else 0
        previous_time = current_time
        
        cv2.putText(img, f"FPS: {int(fps)}", (camera_width - 120, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # é¡¯ç¤ºèªªæ˜ä¿¡æ¯ï¼ˆè‹±æ–‡ï¼‰
        cv2.putText(img, "Press 'q' or 'ESC' to quit | 'h' for help", 
                   (10, camera_height - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # é¡¯ç¤ºå½±åƒ
        cv2.imshow("Hand Gesture Recognition System", img)
        
        # éµç›¤è¼¸å…¥è™•ç†
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q') or key == 27:  # 'q' æˆ– ESC
            print("\n\nç¨‹å¼é€€å‡º")
            break
        elif key == ord('h'):  # å¹«åŠ©
            print("\n" + "=" * 60)
            print("æ‰‹å‹¢è¾¨è­˜ç³»çµ± - å¹«åŠ©ä¿¡æ¯")
            print("=" * 60)
            print("ã€æ•¸å­— 0-9ã€‘")
            for i in range(10):
                print(f"  {i}: {recognizer.get_gesture_description(i)}")
            print("\nã€ç‰¹æ®Šæ‰‹å‹¢ã€‘")
            print(f"  ğŸ‘ Like: {recognizer.get_gesture_description(10)}")
            print(f"  ğŸ‘Œ OK: {recognizer.get_gesture_description(11)}")
            print(f"  ğŸ¤˜ ROCK: {recognizer.get_gesture_description(12)}")
            print(f"  ğŸ–• FUCK: {recognizer.get_gesture_description(13)}")
            print("=" * 60 + "\n")
    
    # æ¸…ç†è³‡æº
    cap.release()
    cv2.destroyAllWindows()
    print("æ”åƒé ­å·²é—œé–‰")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç¨‹å¼è¢«ä¸­æ–·")
    except Exception as e:
        print(f"\néŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

